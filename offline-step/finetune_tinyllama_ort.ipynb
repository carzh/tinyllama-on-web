{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35dc354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from onnxruntime.training import artifacts\n",
    "import onnxruntime.training.api as ort_api\n",
    "import torch\n",
    "import onnx\n",
    "import transformers\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc0eca-01a8-4640-9c05-33bb9ccfc292",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818295ab-2b6a-4621-be90-4c1c7093122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelpath=\"models/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "modelpath=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "dataset_name=\"g-ronimo/oasst2_top1_en\"\n",
    "lr=0.00002      # learning rate\n",
    "bs=2            # batch size\n",
    "bs_eval=16      # batch size for evals\n",
    "ga_steps=16     # gradient acc. steps\n",
    "epochs=4\n",
    "max_length=2048      # samples max. length\n",
    "output_dir=\"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd920d4-6486-491f-afd7-f1c28d5cbb6c",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e867ab6-1b91-45a2-b08e-ec58cd433b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     modelpath,    \n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     # attn_implementation=\"flash_attention_2\",\n",
    "# )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)    # fast tokenizer sometimes ignores added tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccbe5a-4ee1-4615-8e72-8d4103a315b7",
   "metadata": {},
   "source": [
    "# Add ChatML tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ece54e-49ef-4d8b-b957-8b2413eef555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0f765-dd58-40d8-8648-abfe8d157c6c",
   "metadata": {},
   "source": [
    "# Load and prepare OA2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb2dc07d-fddd-4c20-88ed-aeb5c4257ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  24%|██▎       | 1149/4877 [00:04<00:15, 240.74 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (2222 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Map: 100%|██████████| 4877/4877 [00:19<00:00, 246.97 examples/s]\n",
      "Map: 100%|██████████| 542/542 [00:02<00:00, 249.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "# chatML Template and tokenize dataset\n",
    "templates=[\n",
    "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
    "    \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
    "]\n",
    "IGNORE_INDEX=-100\n",
    "\n",
    "def get_position_ids(attention_mask):\n",
    "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
    "\n",
    "    # Shape: (batch_size, sequence_length)\n",
    "    return position_ids\n",
    "\n",
    "# tokenize dataset, set input_ids and attention_mask to train on assistant outputs only\n",
    "def tokenize(input, max_length):\n",
    "    input_ids, attention_mask, position_ids, labels = [], [], [], []\n",
    "\n",
    "    for i,msg in enumerate(input[\"conversation\"]):\n",
    "        isHuman = msg[\"role\"]==\"user\"\n",
    "        msg_chatml=templates[isHuman].format(msg=msg[\"content\"])\n",
    "        msg_tokenized=tokenizer(msg_chatml, truncation=False, add_special_tokens=False)\n",
    "    \n",
    "        input_ids+=msg_tokenized[\"input_ids\"]\n",
    "        attention_mask+=msg_tokenized[\"attention_mask\"]\n",
    "        labels+=[IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids[:max_length],\n",
    "        \"attention_mask\": attention_mask[:max_length],\n",
    "        \"position_ids\": get_position_ids(torch.tensor(attention_mask[:max_length])),\n",
    "        \"labels\": labels[:max_length],\n",
    "    }\n",
    "\n",
    "dataset_tokenized = dataset.map(\n",
    "    partial(tokenize, max_length=max_length), \n",
    "    batched=False, \n",
    "    # num_proc=os.cpu_count(),    # multithreaded\n",
    "    remove_columns=dataset[\"train\"].column_names  # don't need this anymore, we have tokens from here on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d868b086-3863-40eb-a104-fb734bc355f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f26ede-411e-4685-81f4-368a5ecc6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'position_ids', 'labels'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'position_ids', 'labels'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da59e2c-f190-4869-972a-9070c7e6de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
    "def collate(elements):\n",
    "    tokens=[e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen=max([len(t) for t in tokens])\n",
    "\n",
    "    for i,sample in enumerate(elements):\n",
    "        input_ids=sample[\"input_ids\"]\n",
    "        labels=sample[\"labels\"]\n",
    "        position_ids=sample[\"position_ids\"]\n",
    "        attention_mask=sample[\"attention_mask\"]\n",
    "\n",
    "        pad_len=tokens_maxlen-len(input_ids)\n",
    "\n",
    "        input_ids.extend( pad_len * [tokenizer.pad_token_id] )   \n",
    "        labels.extend( pad_len * [IGNORE_INDEX] )    \n",
    "        position_ids.extend( pad_len * [1] )\n",
    "        attention_mask.extend( pad_len * [0] ) \n",
    "\n",
    "    batch={\n",
    "        \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ).numpy(),\n",
    "        \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ).numpy(),\n",
    "        \"position_ids\": torch.tensor( [e[\"position_ids\"] for e in elements] ).numpy(),\n",
    "        # \"position_ids\": position_ids.numpy(),\n",
    "        \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ).numpy(),\n",
    "    }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb54b7cb",
   "metadata": {},
   "source": [
    "# Generating artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22da2774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids (2, 410)\n",
      "labels (2, 410)\n",
      "position_ids (2, 410)\n",
      "attention_mask (2, 410)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# transformers_model = transformers.LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", ignore_mismatched_sizes=True)\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset_tokenized[\"train\"], batch_size=bs, shuffle=True, collate_fn = collate)\n",
    "\n",
    "batch = {}\n",
    "for batch_from_dl in dataloader:\n",
    "    batch = batch_from_dl\n",
    "    break\n",
    "\n",
    "# inputs = (torch.tensor(batch['input_ids'], dtype=torch.int64), torch.tensor(batch['attention_mask'], dtype=torch.int64))\n",
    "# print(inputs[0])\n",
    "# print(inputs[1].shape)\n",
    "\n",
    "for x in batch.keys():\n",
    "    print(x, batch[x].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c27436b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "Data of TensorProto ( tensor name: model.embed_tokens.weight) should be stored in rank_0_TinyLlama-1.1B-Chat-v1.0_decoder_merged_model_fp32.onnx.data, but it doesn't exist or is not accessible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m requires_grad \u001b[38;5;241m=\u001b[39m [param\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m onnx_model\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minitializer] \u001b[38;5;66;03m# if param.name not in requires_grad]\u001b[39;00m\n\u001b[0;32m      4\u001b[0m frozen_params \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m \u001b[43martifacts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_artifacts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43monnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequires_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrozen_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrozen_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# loss=artifacts.LossType.CrossEntropyLoss,\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martifacts_generated_full\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptimType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mort_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_input_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\onnxruntime\\training\\artifacts.py:173\u001b[0m, in \u001b[0;36mgenerate_artifacts\u001b[1;34m(model, requires_grad, frozen_params, loss, optimizer, artifact_directory, prefix, ort_format, custom_op_library, additional_output_names, nominal_checkpoint, loss_input_names)\u001b[0m\n\u001b[0;32m    166\u001b[0m     custom_op_library_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(custom_op_library)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m onnxblock\u001b[38;5;241m.\u001b[39mbase(model), (\n\u001b[0;32m    169\u001b[0m     onnxblock\u001b[38;5;241m.\u001b[39mcustom_op_library(custom_op_library_path)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m custom_op_library \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext()\n\u001b[0;32m    172\u001b[0m ):\n\u001b[1;32m--> 173\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     training_model, eval_model \u001b[38;5;241m=\u001b[39m training_block\u001b[38;5;241m.\u001b[39mto_model_proto()\n\u001b[0;32m    175\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m training_block\u001b[38;5;241m.\u001b[39mparameters()\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\onnxruntime\\training\\onnxblock\\onnxblock.py:188\u001b[0m, in \u001b[0;36mTrainingBlock.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;241m=\u001b[39m accessor\u001b[38;5;241m.\u001b[39m_GLOBAL_ACCESSOR\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    186\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding training block \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m--> 188\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    190\u001b[0m model \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mshape_inference\u001b[38;5;241m.\u001b[39minfer_shapes(accessor\u001b[38;5;241m.\u001b[39m_GLOBAL_ACCESSOR\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m    192\u001b[0m _graph_utils\u001b[38;5;241m.\u001b[39mregister_graph_outputs(model, output)\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\onnxruntime\\training\\artifacts.py:141\u001b[0m, in \u001b[0;36mgenerate_artifacts.<locals>._TrainingBlock.build\u001b[1;34m(self, *inputs_to_loss)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (loss_output, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(additional_output_names))\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs_to_loss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\onnxruntime\\training\\onnxblock\\blocks.py:50\u001b[0m, in \u001b[0;36mBlock.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuilding block: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 50\u001b[0m \u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\tinyllama-full\\lib\\site-packages\\onnx\\checker.py:148\u001b[0m, in \u001b[0;36mcheck_model\u001b[1;34m(model, full_check, skip_opset_compatibility_check)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(protobuf_string) \u001b[38;5;241m>\u001b[39m MAXIMUM_PROTOBUF:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m     )\n\u001b[1;32m--> 148\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotobuf_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_opset_compatibility_check\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValidationError\u001b[0m: Data of TensorProto ( tensor name: model.embed_tokens.weight) should be stored in rank_0_TinyLlama-1.1B-Chat-v1.0_decoder_merged_model_fp32.onnx.data, but it doesn't exist or is not accessible."
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"tinyllama-full-with-export-script/rank_0_TinyLlama-1.1B-Chat-v1.0_decoder_merged_model_fp32.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path, load_external_data=False)\n",
    "requires_grad = [param.name for param in onnx_model.graph.initializer] # if param.name not in requires_grad]\n",
    "frozen_params = []\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    # loss=artifacts.LossType.CrossEntropyLoss,\n",
    "    artifact_directory=\"artifacts_generated_full\",\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    ort_format=False,\n",
    "    loss_input_names=[\"loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f435b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': name: \"loss\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", 'logits': name: \"logits\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"batch_size\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_param: \"sequence_length\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32000\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "name_graph_output_mapping = {output.name: output for output in onnx_model.graph.output}\n",
    "print(name_graph_output_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c7357-6cdc-4355-9b7c-05aa518e214e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c894e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ort_api.CheckpointState.load_checkpoint('artifacts_generated_l1/checkpoint')\n",
    "# training_model = ort_api.Module('artifacts_generated_l1/training_model_corrected_labels.onnx', state, 'artifacts_generated_l1/eval_model.onnx')\n",
    "# optimizer = ort_api.Optimizer('artifacts_generated_l1/optimizer_model.onnx', training_model)\n",
    "\n",
    "state = ort_api.CheckpointState.load_checkpoint('artifacts_generated_full/checkpoint')\n",
    "training_model = ort_api.Module('artifacts_generated_full/training_model.onnx', state, 'artifacts_generated_full/eval_model.onnx')\n",
    "optimizer = ort_api.Optimizer('artifacts_generated_full/optimizer_model.onnx', training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03c7c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_tokenized[\"train\"], batch_size=bs, shuffle=True, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcc0710b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids (2, 1029)\n",
      "labels (2, 1029)\n",
      "position_ids (2, 1029)\n",
      "attention_mask (2, 1029)\n"
     ]
    }
   ],
   "source": [
    "batch = {}\n",
    "for batch_from_dl in dataloader:\n",
    "    batch = batch_from_dl\n",
    "    break\n",
    "\n",
    "# inputs = (torch.tensor(batch['input_ids'], dtype=torch.int64), torch.tensor(batch['attention_mask'], dtype=torch.int64))\n",
    "# print(inputs[0])\n",
    "# print(inputs[1].shape)\n",
    "\n",
    "for x in batch.keys():\n",
    "    print(x, batch[x].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8900b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask', 'position_ids', 'labels']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.input_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f95514b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch():\n",
    "    training_model.train()\n",
    "    losses = []\n",
    "    i = 0\n",
    "    for batch in dataloader:\n",
    "        print(i, 'out of', len(dataloader))\n",
    "        forward_inputs = [batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"position_ids\"], batch[\"labels\"]]\n",
    "        # print(batch.keys())\n",
    "        # print(\"input ids shape\", batch[\"input_ids\"].shape)\n",
    "        # print(\"attention mask shape\", batch[\"attention_mask\"].shape)\n",
    "        # print(\"position_ids shape\", batch[\"position_ids\"].shape)\n",
    "        # print(\"labels shape\", batch[\"labels\"].shape)\n",
    "\n",
    "        loss, _ = training_model(*forward_inputs)\n",
    "        # print('after training acll')\n",
    "        optimizer.step()\n",
    "        training_model.lazy_reset_grad()\n",
    "        losses.append(loss)\n",
    "        print(loss)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ee14fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2439\n",
      "11.074423\n",
      "1 out of 2439\n",
      "10.598811\n",
      "2 out of 2439\n",
      "10.149166\n",
      "3 out of 2439\n",
      "11.018109\n",
      "4 out of 2439\n",
      "10.19532\n",
      "5 out of 2439\n",
      "10.395526\n",
      "6 out of 2439\n",
      "11.050265\n",
      "7 out of 2439\n",
      "9.975668\n",
      "8 out of 2439\n",
      "9.344571\n",
      "9 out of 2439\n",
      "9.393676\n",
      "10 out of 2439\n",
      "9.087124\n",
      "11 out of 2439\n",
      "8.929982\n",
      "12 out of 2439\n",
      "9.041899\n",
      "13 out of 2439\n",
      "8.3379345\n",
      "14 out of 2439\n",
      "8.945558\n",
      "15 out of 2439\n",
      "8.974789\n",
      "16 out of 2439\n",
      "8.334281\n",
      "17 out of 2439\n",
      "8.903706\n",
      "18 out of 2439\n",
      "8.9175825\n",
      "19 out of 2439\n",
      "8.534397\n",
      "20 out of 2439\n",
      "8.369703\n",
      "21 out of 2439\n",
      "7.768069\n",
      "22 out of 2439\n",
      "7.896776\n",
      "23 out of 2439\n",
      "8.12299\n",
      "24 out of 2439\n",
      "8.340614\n",
      "25 out of 2439\n",
      "8.178937\n",
      "26 out of 2439\n",
      "8.498382\n",
      "27 out of 2439\n",
      "7.4799457\n",
      "28 out of 2439\n",
      "4.9762287\n",
      "29 out of 2439\n",
      "7.3726296\n",
      "30 out of 2439\n",
      "8.418573\n",
      "31 out of 2439\n",
      "7.931908\n",
      "32 out of 2439\n",
      "7.957644\n",
      "33 out of 2439\n",
      "7.294777\n",
      "34 out of 2439\n",
      "7.556009\n",
      "35 out of 2439\n",
      "7.756798\n",
      "36 out of 2439\n",
      "7.711334\n",
      "37 out of 2439\n",
      "7.4318843\n",
      "38 out of 2439\n",
      "7.2211747\n",
      "39 out of 2439\n",
      "7.7063537\n",
      "40 out of 2439\n",
      "7.2114935\n",
      "41 out of 2439\n",
      "7.8745465\n",
      "42 out of 2439\n",
      "7.0665956\n",
      "43 out of 2439\n",
      "7.5487447\n",
      "44 out of 2439\n",
      "7.2360296\n",
      "45 out of 2439\n",
      "7.5567217\n",
      "46 out of 2439\n",
      "6.44287\n",
      "47 out of 2439\n",
      "7.9210486\n",
      "48 out of 2439\n",
      "6.9966855\n",
      "49 out of 2439\n",
      "7.783729\n",
      "50 out of 2439\n",
      "8.208576\n",
      "51 out of 2439\n",
      "7.8159785\n",
      "52 out of 2439\n",
      "7.789683\n",
      "53 out of 2439\n",
      "7.735395\n",
      "54 out of 2439\n",
      "7.1787696\n",
      "55 out of 2439\n",
      "7.083399\n",
      "56 out of 2439\n",
      "7.533502\n",
      "57 out of 2439\n",
      "7.3595514\n",
      "58 out of 2439\n",
      "8.235239\n",
      "59 out of 2439\n",
      "7.3169603\n",
      "60 out of 2439\n",
      "6.711804\n",
      "61 out of 2439\n",
      "8.070702\n",
      "62 out of 2439\n",
      "7.0410776\n",
      "63 out of 2439\n",
      "6.5684714\n",
      "64 out of 2439\n",
      "7.313847\n",
      "65 out of 2439\n",
      "7.1127257\n",
      "66 out of 2439\n",
      "7.313229\n",
      "67 out of 2439\n",
      "7.7460313\n",
      "68 out of 2439\n",
      "7.443667\n",
      "69 out of 2439\n",
      "7.3821764\n",
      "70 out of 2439\n",
      "7.973654\n",
      "71 out of 2439\n",
      "7.203531\n",
      "72 out of 2439\n",
      "7.2786283\n",
      "73 out of 2439\n",
      "6.9034\n",
      "74 out of 2439\n",
      "7.934612\n",
      "75 out of 2439\n",
      "6.8656483\n",
      "76 out of 2439\n",
      "7.373701\n",
      "77 out of 2439\n",
      "7.137817\n",
      "78 out of 2439\n",
      "7.6583686\n",
      "79 out of 2439\n",
      "6.7366123\n",
      "80 out of 2439\n",
      "6.798909\n",
      "81 out of 2439\n",
      "7.1800504\n",
      "82 out of 2439\n",
      "7.147073\n",
      "83 out of 2439\n",
      "5.948971\n",
      "84 out of 2439\n",
      "7.6828203\n",
      "85 out of 2439\n",
      "6.860587\n",
      "86 out of 2439\n",
      "6.890707\n",
      "87 out of 2439\n",
      "6.9195848\n",
      "88 out of 2439\n",
      "7.8569074\n",
      "89 out of 2439\n",
      "6.164099\n",
      "90 out of 2439\n",
      "6.9951606\n",
      "91 out of 2439\n",
      "7.385376\n",
      "92 out of 2439\n",
      "7.4716244\n",
      "93 out of 2439\n",
      "7.423824\n",
      "94 out of 2439\n",
      "7.186717\n",
      "95 out of 2439\n",
      "6.633446\n",
      "96 out of 2439\n",
      "6.5545077\n",
      "97 out of 2439\n",
      "6.7745\n",
      "98 out of 2439\n",
      "5.9426613\n",
      "99 out of 2439\n",
      "6.6306973\n",
      "100 out of 2439\n",
      "7.0464554\n",
      "101 out of 2439\n",
      "6.509901\n",
      "102 out of 2439\n",
      "5.289625\n",
      "103 out of 2439\n",
      "7.241798\n",
      "104 out of 2439\n",
      "6.9257793\n",
      "105 out of 2439\n",
      "4.685004\n",
      "106 out of 2439\n",
      "6.4837384\n",
      "107 out of 2439\n",
      "6.7442484\n",
      "108 out of 2439\n",
      "7.1225867\n",
      "109 out of 2439\n",
      "7.83612\n",
      "110 out of 2439\n",
      "6.8207765\n",
      "111 out of 2439\n",
      "6.4633536\n",
      "112 out of 2439\n",
      "6.827272\n",
      "113 out of 2439\n",
      "5.9428186\n",
      "114 out of 2439\n",
      "6.811893\n",
      "115 out of 2439\n",
      "7.3396716\n",
      "116 out of 2439\n",
      "6.987629\n",
      "117 out of 2439\n",
      "6.3369555\n",
      "118 out of 2439\n",
      "6.7755885\n",
      "119 out of 2439\n",
      "7.441386\n",
      "120 out of 2439\n",
      "7.0173874\n",
      "121 out of 2439\n",
      "6.017812\n",
      "122 out of 2439\n",
      "6.7042427\n",
      "123 out of 2439\n",
      "6.5362506\n",
      "124 out of 2439\n",
      "6.3619375\n",
      "125 out of 2439\n",
      "6.885991\n",
      "126 out of 2439\n",
      "9.153843\n",
      "127 out of 2439\n",
      "6.5158854\n",
      "128 out of 2439\n",
      "5.9085755\n",
      "129 out of 2439\n",
      "7.0424104\n",
      "130 out of 2439\n",
      "4.3909645\n",
      "131 out of 2439\n",
      "6.3722067\n",
      "132 out of 2439\n",
      "6.6439476\n",
      "133 out of 2439\n",
      "6.9155135\n",
      "134 out of 2439\n",
      "7.1632986\n",
      "135 out of 2439\n",
      "6.9086676\n",
      "136 out of 2439\n",
      "6.856147\n",
      "137 out of 2439\n",
      "7.332862\n",
      "138 out of 2439\n",
      "5.712775\n",
      "139 out of 2439\n",
      "6.8588424\n",
      "140 out of 2439\n",
      "6.5343957\n",
      "141 out of 2439\n",
      "6.3967075\n",
      "142 out of 2439\n",
      "6.4713674\n",
      "143 out of 2439\n",
      "6.901647\n",
      "144 out of 2439\n",
      "6.142907\n",
      "145 out of 2439\n",
      "6.752628\n",
      "146 out of 2439\n",
      "6.3620815\n",
      "147 out of 2439\n",
      "7.1307697\n",
      "148 out of 2439\n",
      "6.37311\n",
      "149 out of 2439\n",
      "7.529447\n",
      "150 out of 2439\n",
      "6.8464737\n",
      "151 out of 2439\n",
      "6.8765106\n",
      "152 out of 2439\n",
      "5.931408\n",
      "153 out of 2439\n",
      "6.964345\n",
      "154 out of 2439\n",
      "6.3694506\n",
      "155 out of 2439\n",
      "6.7479815\n",
      "156 out of 2439\n",
      "6.373011\n",
      "157 out of 2439\n",
      "6.562133\n",
      "158 out of 2439\n",
      "6.390821\n",
      "159 out of 2439\n",
      "6.082176\n",
      "160 out of 2439\n",
      "6.2624383\n",
      "161 out of 2439\n",
      "6.410218\n",
      "162 out of 2439\n",
      "6.4925804\n",
      "163 out of 2439\n",
      "6.0645013\n",
      "164 out of 2439\n",
      "6.486553\n",
      "165 out of 2439\n",
      "8.000086\n",
      "166 out of 2439\n",
      "6.490837\n",
      "167 out of 2439\n",
      "6.5171633\n",
      "168 out of 2439\n",
      "5.3122873\n",
      "169 out of 2439\n",
      "6.8909273\n",
      "170 out of 2439\n",
      "6.3572607\n",
      "171 out of 2439\n",
      "5.7904015\n",
      "172 out of 2439\n",
      "7.5485864\n",
      "173 out of 2439\n",
      "6.590586\n",
      "174 out of 2439\n",
      "6.391462\n",
      "175 out of 2439\n",
      "6.6656566\n",
      "176 out of 2439\n",
      "5.914743\n",
      "177 out of 2439\n",
      "6.350003\n",
      "178 out of 2439\n",
      "6.4626184\n",
      "179 out of 2439\n",
      "6.267499\n",
      "180 out of 2439\n",
      "6.396264\n",
      "181 out of 2439\n",
      "6.6160073\n",
      "182 out of 2439\n",
      "7.7092314\n",
      "183 out of 2439\n",
      "5.171624\n",
      "184 out of 2439\n",
      "6.1255336\n",
      "185 out of 2439\n",
      "5.6727595\n",
      "186 out of 2439\n",
      "6.5212116\n",
      "187 out of 2439\n",
      "6.039106\n",
      "188 out of 2439\n",
      "7.2674313\n",
      "189 out of 2439\n",
      "6.3064365\n",
      "190 out of 2439\n",
      "5.416792\n",
      "191 out of 2439\n",
      "6.8945045\n",
      "192 out of 2439\n",
      "6.730293\n",
      "193 out of 2439\n",
      "6.481377\n",
      "194 out of 2439\n",
      "6.558999\n",
      "195 out of 2439\n",
      "5.999575\n",
      "196 out of 2439\n",
      "5.7303505\n",
      "197 out of 2439\n",
      "6.7698436\n",
      "198 out of 2439\n",
      "6.5715914\n",
      "199 out of 2439\n",
      "6.5596457\n",
      "200 out of 2439\n",
      "6.2417665\n",
      "201 out of 2439\n",
      "6.602819\n",
      "202 out of 2439\n",
      "6.051511\n",
      "203 out of 2439\n",
      "6.0028396\n",
      "204 out of 2439\n",
      "6.4437118\n",
      "205 out of 2439\n",
      "5.729448\n",
      "206 out of 2439\n",
      "7.069588\n",
      "207 out of 2439\n",
      "8.000498\n",
      "208 out of 2439\n",
      "5.278474\n",
      "209 out of 2439\n",
      "6.368468\n",
      "210 out of 2439\n",
      "6.331041\n",
      "211 out of 2439\n",
      "6.5355806\n",
      "212 out of 2439\n",
      "6.306609\n",
      "213 out of 2439\n",
      "6.4549785\n",
      "214 out of 2439\n",
      "5.001213\n",
      "215 out of 2439\n",
      "7.03419\n",
      "216 out of 2439\n",
      "6.144194\n",
      "217 out of 2439\n",
      "7.1790533\n",
      "218 out of 2439\n",
      "5.5219164\n",
      "219 out of 2439\n",
      "6.5082016\n",
      "220 out of 2439\n",
      "6.180712\n",
      "221 out of 2439\n",
      "6.811513\n",
      "222 out of 2439\n",
      "6.432736\n",
      "223 out of 2439\n",
      "6.2400384\n",
      "224 out of 2439\n",
      "5.891264\n",
      "225 out of 2439\n",
      "5.658552\n",
      "226 out of 2439\n",
      "6.115494\n",
      "227 out of 2439\n",
      "6.524897\n",
      "228 out of 2439\n",
      "6.1440487\n",
      "229 out of 2439\n",
      "6.201476\n",
      "230 out of 2439\n",
      "5.927514\n",
      "231 out of 2439\n",
      "6.1695232\n",
      "232 out of 2439\n",
      "5.8193083\n",
      "233 out of 2439\n",
      "5.746462\n",
      "234 out of 2439\n"
     ]
    }
   ],
   "source": [
    "trainEpoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f12a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"artifacts_generated_l1/training_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78053f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"labels\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"Castloss_dim_0\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32000\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "dim {\n",
      "  dim_param: \"batch_size\"\n",
      "}\n",
      "dim {\n",
      "  dim_param: \"sequence_length\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.graph.input[2])\n",
    "import copy\n",
    "labels_input = copy.deepcopy(model.graph.input[0])\n",
    "labels_input.name = \"labels\"\n",
    "labels_input.type.tensor_type.elem_type = onnx.TensorProto.INT64\n",
    "model.graph.input[2].CopyFrom(labels_input)\n",
    "print(model.graph.input[2].type.tensor_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0775ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(model, \"artifacts_generated_l1/training_model_corrected_labels.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
