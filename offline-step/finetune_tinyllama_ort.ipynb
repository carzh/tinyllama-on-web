{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35dc354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\generate-artifacts-3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from onnxruntime.training import artifacts\n",
    "import onnxruntime.training.api as ort_api\n",
    "import torch\n",
    "import onnx\n",
    "import transformers\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc0eca-01a8-4640-9c05-33bb9ccfc292",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "818295ab-2b6a-4621-be90-4c1c7093122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelpath=\"models/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "modelpath=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "dataset_name=\"g-ronimo/oasst2_top1_en\"\n",
    "lr=0.00002      # learning rate\n",
    "bs=2            # batch size\n",
    "bs_eval=16      # batch size for evals\n",
    "ga_steps=16     # gradient acc. steps\n",
    "epochs=4\n",
    "max_length=2048      # samples max. length\n",
    "output_dir=\"out\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd920d4-6486-491f-afd7-f1c28d5cbb6c",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e867ab6-1b91-45a2-b08e-ec58cd433b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     modelpath,    \n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     # attn_implementation=\"flash_attention_2\",\n",
    "# )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)    # fast tokenizer sometimes ignores added tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccbe5a-4ee1-4615-8e72-8d4103a315b7",
   "metadata": {},
   "source": [
    "# Add ChatML tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71ece54e-49ef-4d8b-b957-8b2413eef555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n",
    "tokenizer.pad_token = \"<PAD>\"\n",
    "tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd0f765-dd58-40d8-8648-abfe8d157c6c",
   "metadata": {},
   "source": [
    "# Load and prepare OA2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb2dc07d-fddd-4c20-88ed-aeb5c4257ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4877/4877 [00:06<00:00, 759.76 examples/s]\n",
      "Map: 100%|██████████| 542/542 [00:00<00:00, 742.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "# chatML Template and tokenize dataset\n",
    "templates=[\n",
    "    \"<|im_start|>assistant\\n{msg}<|im_end|>\",\n",
    "    \"<|im_start|>user\\n{msg}<|im_end|>\"\n",
    "]\n",
    "IGNORE_INDEX=-100\n",
    "\n",
    "def get_position_ids(attention_mask):\n",
    "    position_ids = attention_mask.long().cumsum(-1) - 1\n",
    "    position_ids.masked_fill_(attention_mask == 0, 1)\n",
    "\n",
    "    # Shape: (batch_size, sequence_length)\n",
    "    return position_ids\n",
    "\n",
    "# tokenize dataset, set input_ids and attention_mask to train on assistant outputs only\n",
    "def tokenize(input, max_length):\n",
    "    input_ids, attention_mask, position_ids, labels = [], [], [], []\n",
    "\n",
    "    for i,msg in enumerate(input[\"conversation\"]):\n",
    "        isHuman = msg[\"role\"]==\"user\"\n",
    "        msg_chatml=templates[isHuman].format(msg=msg[\"content\"])\n",
    "        msg_tokenized=tokenizer(msg_chatml, truncation=False, add_special_tokens=False)\n",
    "    \n",
    "        input_ids+=msg_tokenized[\"input_ids\"]\n",
    "        attention_mask+=msg_tokenized[\"attention_mask\"]\n",
    "        labels+=[IGNORE_INDEX]*len(msg_tokenized[\"input_ids\"]) if isHuman else msg_tokenized[\"input_ids\"]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids[:max_length],\n",
    "        \"attention_mask\": attention_mask[:max_length],\n",
    "        \"position_ids\": get_position_ids(torch.tensor(attention_mask[:max_length])),\n",
    "        \"labels\": labels[:max_length],\n",
    "    }\n",
    "\n",
    "dataset_tokenized = dataset.map(\n",
    "    partial(tokenize, max_length=max_length), \n",
    "    batched=False, \n",
    "    # num_proc=os.cpu_count(),    # multithreaded\n",
    "    remove_columns=dataset[\"train\"].column_names  # don't need this anymore, we have tokens from here on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d868b086-3863-40eb-a104-fb734bc355f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['conversation'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45f26ede-411e-4685-81f4-368a5ecc6b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'position_ids', 'labels'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'position_ids', 'labels'],\n",
       "        num_rows: 542\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2da59e2c-f190-4869-972a-9070c7e6de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_ids: [..], labels: [..], attention_mask: [..] }\n",
    "def collate(elements):\n",
    "    tokens=[e[\"input_ids\"] for e in elements]\n",
    "    tokens_maxlen=max([len(t) for t in tokens])\n",
    "\n",
    "    for i,sample in enumerate(elements):\n",
    "        input_ids=sample[\"input_ids\"]\n",
    "        labels=sample[\"labels\"]\n",
    "        attention_mask=sample[\"attention_mask\"]\n",
    "\n",
    "        pad_len=tokens_maxlen-len(input_ids)\n",
    "\n",
    "        input_ids.extend( pad_len * [tokenizer.pad_token_id] )   \n",
    "        labels.extend( pad_len * [IGNORE_INDEX] )    \n",
    "        attention_mask.extend( pad_len * [0] ) \n",
    "\n",
    "    batch={\n",
    "        \"input_ids\": torch.tensor( [e[\"input_ids\"] for e in elements] ).numpy(),\n",
    "        \"labels\": torch.tensor( [e[\"labels\"] for e in elements] ).numpy(),\n",
    "        \"position_ids\": torch.tensor( [e[\"position_ids\"] for e in elements] ).numpy(),\n",
    "        \"attention_mask\": torch.tensor( [e[\"attention_mask\"] for e in elements] ).numpy(),\n",
    "    }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb54b7cb",
   "metadata": {},
   "source": [
    "# Generating artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22da2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformers_model = transformers.LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", ignore_mismatched_sizes=True)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset_tokenized[\"train\"], batch_size=bs, shuffle=True, collate_fn = collate)\n",
    "\n",
    "batch = {}\n",
    "for batch_from_dl in dataloader:\n",
    "    batch = batch_from_dl\n",
    "    break\n",
    "\n",
    "# inputs = (torch.tensor(batch['input_ids'], dtype=torch.int64), torch.tensor(batch['attention_mask'], dtype=torch.int64))\n",
    "# print(inputs[0])\n",
    "# print(inputs[1].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c27436b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = \"tinyllama-with-export-script/rank_0_TinyLlama-1.1B-Chat-v1.0_decoder_merged_model_fp32.onnx\"\n",
    "onnx_model = onnx.load(onnx_model_path)\n",
    "requires_grad = [param.name for param in onnx_model.graph.initializer] # if param.name not in requires_grad]\n",
    "frozen_params = []\n",
    "artifacts.generate_artifacts(\n",
    "    onnx_model,\n",
    "    requires_grad=requires_grad,\n",
    "    frozen_params=frozen_params,\n",
    "    # loss=artifacts.LossType.CrossEntropyLoss,\n",
    "    artifact_directory=\"artifacts_generated_full\",\n",
    "    optimizer=artifacts.OptimType.AdamW,\n",
    "    ort_format=False,\n",
    "    # loss_input_names=[\"loss\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c7357-6cdc-4355-9b7c-05aa518e214e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c894e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = ort_api.CheckpointState.load_checkpoint('artifacts_generated_l1/checkpoint')\n",
    "# training_model = ort_api.Module('artifacts_generated_l1/training_model_corrected_labels.onnx', state, 'artifacts_generated_l1/eval_model.onnx')\n",
    "# optimizer = ort_api.Optimizer('artifacts_generated_l1/optimizer_model.onnx', training_model)\n",
    "\n",
    "state = ort_api.CheckpointState.load_checkpoint('artifacts_generated_full/checkpoint')\n",
    "training_model = ort_api.Module('artifacts_generated_full/training_model.onnx', state, 'artifacts_generated_full/eval_model.onnx')\n",
    "optimizer = ort_api.Optimizer('artifacts_generated_full/optimizer_model.onnx', training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03c7c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset_tokenized[\"train\"], batch_size=bs, shuffle=True, collate_fn = collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8900b0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'attention_mask',\n",
       " 'position_ids',\n",
       " 'past_key_values.0.key',\n",
       " 'past_key_values.0.value',\n",
       " 'labels']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.input_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f95514b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch():\n",
    "    training_model.train()\n",
    "    losses = []\n",
    "    i = 0\n",
    "    for batch in dataloader:\n",
    "        print(i, 'out of', len(dataloader))\n",
    "        forward_inputs = [batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]]\n",
    "        print(\"input ids shape\", batch[\"input_ids\"].shape)\n",
    "        print(\"attention mask shape\", batch[\"attention_mask\"].shape)\n",
    "        print(\"labels shape\", batch[\"labels\"].shape)\n",
    "\n",
    "        loss, _ = training_model(*forward_inputs)\n",
    "        print('after training acll')\n",
    "        optimizer.step()\n",
    "        training_model.lazy_reset_grad()\n",
    "        losses.append(loss)\n",
    "        print(loss)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ee14fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 2439\n",
      "input ids shape (2, 162)\n",
      "attention mask shape (2, 162)\n",
      "labels shape (2, 162)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "C:\\a\\_work\\1\\s\\orttraining\\orttraining\\training_api\\module.cc:538 onnxruntime::training::api::Module::TrainStep [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : feed names has 31 elements, but feed has 28 elements.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 12\u001b[0m, in \u001b[0;36mtrainEpoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention mask shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 12\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter training acll\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\generate-artifacts-3\\lib\\site-packages\\onnxruntime\\training\\api\\module.py:113\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *user_inputs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(OrtValue(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m fetches)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_np_input(user_inputs):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_generic_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43muser_inputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_step_with_ortvalues(user_inputs)\n",
      "File \u001b[1;32mc:\\Users\\carolinezhu\\AppData\\Local\\anaconda3\\envs\\generate-artifacts-3\\lib\\site-packages\\onnxruntime\\training\\api\\module.py:85\u001b[0m, in \u001b[0;36mModule.__call__.<locals>._take_generic_step\u001b[1;34m(forward_inputs)\u001b[0m\n\u001b[0;32m     83\u001b[0m fetches \u001b[38;5;241m=\u001b[39m OrtValueVector()\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39meval_step(forward_inputs, fetches)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: C:\\a\\_work\\1\\s\\orttraining\\orttraining\\training_api\\module.cc:538 onnxruntime::training::api::Module::TrainStep [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : feed names has 31 elements, but feed has 28 elements.\n"
     ]
    }
   ],
   "source": [
    "trainEpoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f12a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"artifacts_generated_l1/training_model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78053f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"labels\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 7\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_param: \"Castloss_dim_0\"\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 32000\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "dim {\n",
      "  dim_param: \"batch_size\"\n",
      "}\n",
      "dim {\n",
      "  dim_param: \"sequence_length\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.graph.input[2])\n",
    "import copy\n",
    "labels_input = copy.deepcopy(model.graph.input[0])\n",
    "labels_input.name = \"labels\"\n",
    "labels_input.type.tensor_type.elem_type = onnx.TensorProto.INT64\n",
    "model.graph.input[2].CopyFrom(labels_input)\n",
    "print(model.graph.input[2].type.tensor_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0775ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(model, \"artifacts_generated_l1/training_model_corrected_labels.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
